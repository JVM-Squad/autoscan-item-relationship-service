= Operational concepts

== Administration

=== Configuration
The IRS can be configured using two mechanisms:

==== application.yml
If you build the IRS yourself, you can modify the application.yml config that is shipped with the IRS.
This file contains all possible config entries for the application.
Once the Docker image has been built, these values can only be overwritten using the
Spring Boot externalized configuration mechanism,
e.g. by mounting a config file in the right path or using environment variables.

==== Helm Chart
The most relevant config properties are exposed as environment variables and must be set
in the https://helm.sh/[Helm] chart so the application can run at all.
Check the IRS Helm chart in Git for all available variables.

== Disaster-Recovery

=== Ephemeral components
All components in the IRS deployment not listed in the persistent components section below are considered ephemeral
and are easily replaced in a disaster scenario.
All deployment components are described using Helm charts,
which can be used to restore the deployment with the Docker images.
Should the Docker images go missing, they can be restored by executing the build pipelines
for the corresponding version tag of the component.

=== Persistent components
These components utilize data persistence, which needs to be backed up separately by the operator.

- *Minio persistent volume*: Contains the stored Job information. In case of data loss, Jobs can be started again to retrieve the data from the network.
- *Prometheus persistent volume*: Contains the monitoring data of the IRS. In case of data loss, no analysis can be done for past timeframes.
- *Vault secrets*: In case of data loss, the credentials stored in the Vault need to be recreated manually. See the deployment view for an overview.

== Scaling
If the number of consumers raises, the IRS can be scaled up by using more resources for the Deployment Pod.
Those resources can be used to utilize more parallel threads to handle Job execution.

== Clustering
The IRS can run in clustered mode, as each running job is only present in one pod at a time.
Note: as soon as a resume feature is implemented, this needs to be addressed here.

== Logging
Logs are being written directly to stdout and are picked up by the cluster management.

== Monitoring
The application can be monitored using https://prometheus.io/[Prometheus] and https://grafana.com/[Grafana].
Both systems are defined in the Helm charts with a default setup.
A number of Grafana dashboards are deployed automatically, to display data about:

- Pod / JVM resources
- API metrics
- Functional information about IRS Jobs